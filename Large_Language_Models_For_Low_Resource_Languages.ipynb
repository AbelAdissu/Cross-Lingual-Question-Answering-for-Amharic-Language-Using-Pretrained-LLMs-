{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMuao43NwEWG0Appanac1Hg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quinbez/Large_Language_Models_For_Low_Resource_Languages/blob/main/Large_Language_Models_For_Low_Resource_Languages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Downloading Dataset**"
      ],
      "metadata": {
        "id": "koi97YuzAO9o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1p1QxCIgeH",
        "outputId": "d035428f-96ca-4086-f133-7d69601f10b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/raw-corpus.txt'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "lines = open(file_path, encoding='utf-8').read().split('\\n')\n",
        "data = pd.DataFrame({'Text': lines})\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "Dm3pWI-8Iy3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641d376f-86ae-480b-be87-f6374b54bfac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text\n",
            "0                     ዛሬ ነገ ሳንል መነሳት የዜግነት ግዴታችን ነው!\n",
            "1                                  አብዶ ኑር የሱፍ (ኖርዌ) \n",
            "2                    ዛሬ ነገ ሳንል መነሳት የዜግነት ግዴታችን ነው! \n",
            "3                                ከአብዶ ኑር የሱፍ (ኖርዌይ) \n",
            "4   ለቀድሞው  የወያኔ  ጠቅላይ ሚኒስትር  ለጊዜው ኳሷ በእሳቸው ቁጥጥር ስ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre-Processing**"
      ],
      "metadata": {
        "id": "ftCbKYKwJFet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Replace words that are not amharic with 'unk'. Example: she said ልክ ነው -> unk unk ልክ ነው\n",
        "* Replace consecutive 'unk' with just one 'unk'. Example: she said ልክ ነው -> unk ልክ ነው\n",
        "* Add spaces around punctuations. Example: ቻው! -> ቻው !\n",
        "* Replace consecutive same punctuations by just one. Example: %%% -> %\n",
        "* Truncate words that have more than 13 characters to just 13\n",
        "* Replace characters other than arabic digits and amharic characters with 'u'. Example: እንሂድxc -> እንሂድuu\n",
        "* Normalize by replacing characters and words by using the mapping in the replace file"
      ],
      "metadata": {
        "id": "12SmEFzqJJuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace words that are not amharic with 'unk'. Example: she said ልክ ነው -> unk unk ልክ ነው\n",
        "# Replace consecutive 'unk' with just one 'unk'. Example: she said ልክ ነው -> unk ልክ ነው\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def is_amharic(word):\n",
        "    return re.fullmatch(r'[\\u1200-\\u137F]+', word) is not None\n",
        "\n",
        "def replace_non_amharic(text):\n",
        "    words = text.split()\n",
        "    replaced_words = []\n",
        "    prev_word = None\n",
        "    for word in words:\n",
        "        if is_amharic(word):\n",
        "            replaced_words.append(word)\n",
        "            prev_word = word\n",
        "        elif prev_word != 'unk':\n",
        "            replaced_words.append('unk')\n",
        "            prev_word = 'unk'\n",
        "    return ' '.join(replaced_words)\n",
        "\n",
        "data['Text'] = data['Text'].apply(replace_non_amharic)"
      ],
      "metadata": {
        "id": "hSBo8hb8JwJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "id": "qSx63hqPJ890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46803fb-c5f6-400e-898b-1a823af4e110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text\n",
            "0                     ዛሬ ነገ ሳንል መነሳት የዜግነት ግዴታችን unk\n",
            "1                                     አብዶ ኑር የሱፍ unk\n",
            "2                     ዛሬ ነገ ሳንል መነሳት የዜግነት ግዴታችን unk\n",
            "3                                    ከአብዶ ኑር የሱፍ unk\n",
            "4  ለቀድሞው የወያኔ ጠቅላይ ሚኒስትር ለጊዜው ኳሷ በእሳቸው ቁጥጥር ስር እን...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.tail())"
      ],
      "metadata": {
        "id": "URh_SnnzJ9k1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdec59e6-ea0e-4e3b-b3d8-3a1f105a7fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Text\n",
            "557348  unk\n",
            "557349  unk\n",
            "557350  unk\n",
            "557351  unk\n",
            "557352     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add spaces around punctuations. Example: ቻው! -> ቻው !\n",
        "\n",
        "def space_around_punctuation(text):\n",
        "    return re.sub(r'([።፣፤፥፦፧፨!\\\"#$%&\\'()*+,-./:;<=>?@\\[\\\\\\]^_`{|}~])', r' \\1 ', text)\n",
        "\n",
        "data['Text'] = data['Text'].apply(space_around_punctuation)"
      ],
      "metadata": {
        "id": "mzU3bFvbKtpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[:6])"
      ],
      "metadata": {
        "id": "Bdc4Bl8-Kwlf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a30fd8-2e02-4a5b-be3f-a1dad1e69c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text\n",
            "0                     ዛሬ ነገ ሳንል መነሳት የዜግነት ግዴታችን unk\n",
            "1                                     አብዶ ኑር የሱፍ unk\n",
            "2                     ዛሬ ነገ ሳንል መነሳት የዜግነት ግዴታችን unk\n",
            "3                                    ከአብዶ ኑር የሱፍ unk\n",
            "4  ለቀድሞው የወያኔ ጠቅላይ ሚኒስትር ለጊዜው ኳሷ በእሳቸው ቁጥጥር ስር እን...\n",
            "5  ምፈልገው ወገን ጋር ልጫወትባት  ፣  ስለ ኳሷ አትጠይቁኝ  ፣  ወደ ኳሷ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace consecutive same punctuations by just one. Example: %%% -> %\n",
        "\n",
        "import re\n",
        "def replace_consecutive_punctuation(text):\n",
        "    return re.sub(r'(\\W)\\1+', r'\\1', text)\n",
        "\n",
        "data['Text'] = data['Text'].apply(replace_consecutive_punctuation)"
      ],
      "metadata": {
        "id": "OEYuvTp_K4Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[17:25])"
      ],
      "metadata": {
        "id": "gqgy9zNGLPV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b361ca-d449-40d5-f375-085756decb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 Text\n",
            "17  ራስ ወዳዱ ጠቅላይ ሚኒስትር በሞት ከተለዩ በኋላ እንደተካሄደው አይነት የ...\n",
            "18                          ኢ ትዮጵያ በክብር ለዘላለም ትኑር unk\n",
            "19                                       ለአስተያየቶት unk\n",
            "20                   ግራ የሚያጋባ የወቅቱ unk ማብቂያውን እናፍቃለሁ፡\n",
            "21                   ግራ የሚያጋባ የወቅቱ unk ማብቂያውን እናፍቃለሁ፡\n",
            "22                                                   \n",
            "23                                        በማሕሌት ፋንታሁን\n",
            "24  በሕይወታችን የምናደርጋቸውን እንቅስቃሴዎች ከመከወን እንድንቆጠብ ለራሳችን...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate words that have more than 13 characters to just 13\n",
        "\n",
        "# def truncate_long_words(text, max_length=13):\n",
        "#     words = text.split()\n",
        "#     truncated_words = [word if len(word) <= max_length else word[:max_length] for word in words]\n",
        "#     return ' '.join(truncated_words)\n",
        "\n",
        "# data['Text'] = data['Text'].apply(truncate_long_words)\n",
        "# print(len(data))"
      ],
      "metadata": {
        "id": "i93Vj3NiLwRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace characters other than arabic digits and amharic characters with 'u'. Example: እንሂድxc -> እንሂድuu\n",
        "\n",
        "import re\n",
        "def replace_non_charset_with_u(text):\n",
        "    tokens = re.split(r'(unk)', text, flags=re.IGNORECASE)\n",
        "    pattern = r\"[^\\u1200-\\u137F\\u1369-\\u137C0-9\\s]+\"\n",
        "\n",
        "    processed_tokens = [\n",
        "        re.sub(pattern, 'u', token) if token.lower() != 'unk' else token\n",
        "        for token in tokens\n",
        "    ]\n",
        "    return ''.join(processed_tokens)\n",
        "\n",
        "data['Text'] = data['Text'].apply(lambda text: replace_non_charset_with_u(text))\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "m1hKzwf6MG5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b1ec8d-f166-499a-e0e0-ae0b8365676a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text\n",
            "0                     ዛሬ ነገ ሳንል መነሳት የዜግነት ግዴታችን ነውu\n",
            "1                                  አብዶ ኑር የሱፍ uኖርዌu \n",
            "2                    ዛሬ ነገ ሳንል መነሳት የዜግነት ግዴታችን ነውu \n",
            "3                                ከአብዶ ኑር የሱፍ uኖርዌይu \n",
            "4   ለቀድሞው  የወያኔ  ጠቅላይ ሚኒስትር  ለጊዜው ኳሷ በእሳቸው ቁጥጥር ስ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize by replacing characters and words by using the mapping in the replace file\n",
        "\n",
        "def load_mapping(file_path):\n",
        "    mapping = {}\n",
        "    with open(file_path, 'r',  encoding='latin-1') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split('=')\n",
        "            if len(parts) == 2:\n",
        "                key, value = parts\n",
        "                mapping[key] = value\n",
        "    return mapping\n",
        "def normalize_text(text, mapping):\n",
        "    for key, value in mapping.items():\n",
        "        text = text.replace(key, value)\n",
        "    return text\n",
        "\n",
        "mapping = load_mapping(\"/content/drive/MyDrive/replace.txt\")\n",
        "data['Text'] = data['Text'].apply(lambda x: normalize_text(x, mapping))"
      ],
      "metadata": {
        "id": "TDubpsv_MdYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[45:50])"
      ],
      "metadata": {
        "id": "0DfLPQhvMniE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tokenization**"
      ],
      "metadata": {
        "id": "0tBz8ZQnNe1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def create_char_mappings(text):\n",
        "    chars = sorted(list(set(text)))\n",
        "    vocab_size = len(chars)\n",
        "    stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "    itos = {i: ch for i, ch in enumerate(chars)}\n",
        "    return stoi, itos, len(chars)\n",
        "\n",
        "# Function to encode a string using the mapping\n",
        "def encode_string(s, stoi):\n",
        "    return [stoi[c] for c in s ]\n",
        "\n",
        "def decode_string(encoded_list, mapping):\n",
        "    return ''.join([mapping.get(i, '?') for i in encoded_list])\n",
        "\n",
        "# Convert the list to a DataFrame\n",
        "data = pd.DataFrame(lines, columns=['Text'])\n",
        "\n",
        "# Concatenate all text into a single string\n",
        "all_text = ''.join(data['Text'].tolist())\n",
        "\n",
        "# Create the mappings\n",
        "stoi, itos, vocab_size = create_char_mappings(all_text)\n",
        "\n",
        "# Encode the entire text using the provided function\n",
        "encoded_text = encode_string(all_text, stoi)\n",
        "\n",
        "decoded_text = decode_string(encoded_text, itos)\n",
        "\n",
        "# Convert the encoded text into a tensor\n",
        "data_tensor = torch.tensor(encoded_text, dtype=torch.long)\n",
        "\n",
        "print(data_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcdq9RHPNhgq",
        "outputId": "11d3f060-ac55-4b35-d6e8-8ad5d4cae291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([549, 394,  17,  ...,  97,  97,  31])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data into Training and Validation\n",
        "\n",
        "def split_data(text, split_ratio=0.9):\n",
        "    n = int(split_ratio * len(data_tensor))\n",
        "    train_data = data_tensor[:n]\n",
        "    val_data = data_tensor[n:]\n",
        "\n",
        "    return train_data, val_data\n",
        "train_data, val_data = split_data(data, split_ratio = 0.9)\n",
        "print(len(train_data))\n",
        "print(len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS9r8Yu0NrGD",
        "outputId": "2684a72a-9787-4218-e7bb-b13e58d75361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161594799\n",
            "17954978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DataLoader**"
      ],
      "metadata": {
        "id": "7qJnS16pNu1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch\n",
        "\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "train_x, train_y = get_batch('train')\n",
        "val_x, val_y = get_batch('val')\n",
        "print(\"Training Batch - Input (x): \\n\", train_x)\n",
        "print(\"\\nTraining Batch - Target (y): \\n\", train_y)\n",
        "print(\"\\nValidation Batch - Input (x): \\n\", val_x)\n",
        "print(\"\\nValidation Batch - Target (y): \\n\", val_y)"
      ],
      "metadata": {
        "id": "mUaa9oCVt9S8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b07321-b4c8-443f-a00b-cf6ff0a67a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Batch - Input (x): \n",
            " tensor([[484, 457, 675, 675, 355, 567, 530, 457],\n",
            "        [510, 457,  17, 497, 363, 570, 390, 398],\n",
            "        [363,  17, 502, 486, 570, 356, 481,  17],\n",
            "        [390, 403,  17, 530, 575, 414, 535,  17],\n",
            "        [454, 379,  17, 570, 390, 589,  17, 562],\n",
            "        [502, 548, 355,  17, 481, 619, 441,  17],\n",
            "        [100,  17,  90,  95, 103,  86,  95, 101],\n",
            "        [395, 399,  17, 358, 374, 505, 361, 505],\n",
            "        [465, 361, 363, 675, 675,  17, 567, 355],\n",
            "        [460, 535, 484,  17, 530, 570,  17, 414],\n",
            "        [515, 395, 456, 457,  17, 502, 486, 570],\n",
            "        [ 17, 438, 396,  17, 436, 452, 358, 565],\n",
            "        [374, 570, 358, 565,  17, 356, 573, 460],\n",
            "        [530, 617, 458, 465,  17, 436, 599, 659],\n",
            "        [659, 459, 363,  17, 436, 376, 363,  17],\n",
            "        [ 17, 502, 486, 570, 452, 484, 594, 391],\n",
            "        [439, 437, 391,  17, 497, 572, 403,  17],\n",
            "        [565, 403, 390, 573, 535, 677,  17, 562],\n",
            "        [355, 530, 369, 457,  17, 597, 395,  17],\n",
            "        [567, 457,  17, 497, 419, 395, 443, 363],\n",
            "        [575,  17, 497, 436, 597, 551,  17,  26],\n",
            "        [ 17, 436, 535, 627,  17, 497, 594, 395],\n",
            "        [359,  17, 562, 499, 457, 568, 635, 565],\n",
            "        [486,  17, 575, 486, 594, 457,  17, 505],\n",
            "        [ 17, 374, 363, 403,  17, 575, 379, 395],\n",
            "        [436, 395, 543, 402,  17, 562, 614, 414],\n",
            "        [ 17, 595, 573, 567,  17, 502, 403, 508],\n",
            "        [441, 353, 457,  17, 436, 403, 375,  17],\n",
            "        [ 17, 562, 401, 419,  17, 375, 359,  17],\n",
            "        [358, 535, 675, 675,  17, 562, 379, 486],\n",
            "        [599, 361, 460, 535,  17, 497, 486, 453],\n",
            "        [535, 567, 567, 458, 465,  17, 502, 486]])\n",
            "\n",
            "Training Batch - Target (y): \n",
            " tensor([[457, 675, 675, 355, 567, 530, 457,  17],\n",
            "        [457,  17, 497, 363, 570, 390, 398, 494],\n",
            "        [ 17, 502, 486, 570, 356, 481,  17, 436],\n",
            "        [403,  17, 530, 575, 414, 535,  17, 393],\n",
            "        [379,  17, 570, 390, 589,  17, 562, 452],\n",
            "        [548, 355,  17, 481, 619, 441,  17, 361],\n",
            "        [ 17,  90,  95, 103,  86,  95, 101,  86],\n",
            "        [399,  17, 358, 374, 505, 361, 505, 363],\n",
            "        [361, 363, 675, 675,  17, 567, 355, 379],\n",
            "        [535, 484,  17, 530, 570,  17, 414, 486],\n",
            "        [395, 456, 457,  17, 502, 486, 570,  17],\n",
            "        [438, 396,  17, 436, 452, 358, 565, 563],\n",
            "        [570, 358, 565,  17, 356, 573, 460, 535],\n",
            "        [617, 458, 465,  17, 436, 599, 659,  17],\n",
            "        [459, 363,  17, 436, 376, 363,  17, 358],\n",
            "        [502, 486, 570, 452, 484, 594, 391, 457],\n",
            "        [437, 391,  17, 497, 572, 403,  17, 497],\n",
            "        [403, 390, 573, 535, 677,  17, 562, 439],\n",
            "        [530, 369, 457,  17, 597, 395,  17, 436],\n",
            "        [457,  17, 497, 419, 395, 443, 363, 675],\n",
            "        [ 17, 497, 436, 597, 551,  17,  26, 353],\n",
            "        [436, 535, 627,  17, 497, 594, 395,  17],\n",
            "        [ 17, 562, 499, 457, 568, 635, 565,  17],\n",
            "        [ 17, 575, 486, 594, 457,  17, 505, 355],\n",
            "        [374, 363, 403,  17, 575, 379, 395,  17],\n",
            "        [395, 543, 402,  17, 562, 614, 414, 403],\n",
            "        [595, 573, 567,  17, 502, 403, 508, 351],\n",
            "        [353, 457,  17, 436, 403, 375,  17, 594],\n",
            "        [562, 401, 419,  17, 375, 359,  17, 481],\n",
            "        [535, 675, 675,  17, 562, 379, 486,  17],\n",
            "        [361, 460, 535,  17, 497, 486, 453,  17],\n",
            "        [567, 567, 458, 465,  17, 502, 486, 570]])\n",
            "\n",
            "Validation Batch - Input (x): \n",
            " tensor([[436, 398, 505, 481,  17, 374, 486, 654],\n",
            "        [394, 457,  17, 361, 393, 407,  17, 619],\n",
            "        [510, 403,  17, 440, 452, 510, 395, 403],\n",
            "        [455, 572, 565,  17, 374, 486, 599, 403],\n",
            "        [355,  17, 390, 594, 575,  17, 562, 452],\n",
            "        [358, 452, 505, 436, 390,  17, 350, 594],\n",
            "        [502, 484,  17, 371, 599,  17, 502, 484],\n",
            "        [358, 675, 675,  17, 374, 464,  17, 502],\n",
            "        [403, 619,  17, 594, 438,  17, 436, 377],\n",
            "        [ 17, 497, 594, 395,  17, 535, 403, 619],\n",
            "        [356, 482,  17, 363, 439, 465, 351,  17],\n",
            "        [374, 356, 486,  17, 567, 355, 486,  17],\n",
            "        [ 17, 436, 374, 387, 597, 459,  17, 481],\n",
            "        [486,  17, 562, 665, 395, 454, 565, 465],\n",
            "        [356, 573, 460, 535,  17, 130,  17, 562],\n",
            "        [502, 395, 599, 551, 484, 486,  17, 452],\n",
            "        [403, 436, 361, 457,  17, 130,  17,  17],\n",
            "        [439, 486, 572, 393,  17, 377, 535, 358],\n",
            "        [ 17, 436, 374, 374, 508, 505, 395,  17],\n",
            "        [ 17, 562, 659, 419, 395,  17, 371, 567],\n",
            "        [570,  17, 576, 395, 376, 452, 392,  17],\n",
            "        [403, 358, 374, 356, 482,  17, 452, 481],\n",
            "        [376, 486, 414, 401, 414, 403, 436, 457],\n",
            "        [619, 397, 363, 675, 675,  17, 599, 547],\n",
            "        [ 25,  94,  90,  95,  30, 104,  90,  85],\n",
            "        [ 17, 497, 377, 396, 465,  17, 505, 497],\n",
            "        [565, 403, 455, 530, 398,  17, 502, 484],\n",
            "        [457,  17, 452, 622, 439, 627,  17, 519],\n",
            "        [ 17, 575, 379, 643,  17, 505, 562, 457],\n",
            "        [ 17, 497, 363, 594, 437, 379,  43,  43],\n",
            "        [657, 487, 536, 465, 677,  17, 562, 497],\n",
            "        [377, 486, 481, 457, 486, 484,  17, 441]])\n",
            "\n",
            "Validation Batch - Target (y): \n",
            " tensor([[398, 505, 481,  17, 374, 486, 654, 403],\n",
            "        [457,  17, 361, 393, 407,  17, 619, 565],\n",
            "        [403,  17, 440, 452, 510, 395, 403, 454],\n",
            "        [572, 565,  17, 374, 486, 599, 403, 457],\n",
            "        [ 17, 390, 594, 575,  17, 562, 452, 398],\n",
            "        [452, 505, 436, 390,  17, 350, 594, 393],\n",
            "        [484,  17, 371, 599,  17, 502, 484,  17],\n",
            "        [675, 675,  17, 374, 464,  17, 502, 486],\n",
            "        [619,  17, 594, 438,  17, 436, 377, 401],\n",
            "        [497, 594, 395,  17, 535, 403, 619,  17],\n",
            "        [482,  17, 363, 439, 465, 351,  17, 497],\n",
            "        [356, 486,  17, 567, 355, 486,  17, 543],\n",
            "        [436, 374, 387, 597, 459,  17, 481, 535],\n",
            "        [ 17, 562, 665, 395, 454, 565, 465, 486],\n",
            "        [573, 460, 535,  17, 130,  17, 562, 452],\n",
            "        [395, 599, 551, 484, 486,  17, 452, 505],\n",
            "        [436, 361, 457,  17, 130,  17,  17, 562],\n",
            "        [486, 572, 393,  17, 377, 535, 358, 441],\n",
            "        [436, 374, 374, 508, 505, 395,  17, 374],\n",
            "        [562, 659, 419, 395,  17, 371, 567, 530],\n",
            "        [ 17, 576, 395, 376, 452, 392,  17, 358],\n",
            "        [358, 374, 356, 482,  17, 452, 481, 599],\n",
            "        [486, 414, 401, 414, 403, 436, 457,  17],\n",
            "        [397, 363, 675, 675,  17, 599, 547, 655],\n",
            "        [ 94,  90,  95,  30, 104,  90,  85, 101],\n",
            "        [497, 377, 396, 465,  17, 505, 497, 377],\n",
            "        [403, 455, 530, 398,  17, 502, 484,  17],\n",
            "        [ 17, 452, 622, 439, 627,  17, 519, 485],\n",
            "        [575, 379, 643,  17, 505, 562, 457, 492],\n",
            "        [497, 363, 594, 437, 379,  43,  43, 502],\n",
            "        [487, 536, 465, 677,  17, 562, 497, 659],\n",
            "        [486, 481, 457, 486, 484,  17, 441, 354]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for b in range(batch_size):\n",
        "    for t in range(block_size):\n",
        "        context = train_x[b, :t+1]\n",
        "        target = train_y[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNOQaEPZfX-p",
        "outputId": "6e80c47c-04f6-4ea0-85a6-77ca5c6495c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is [484] the target: 457\n",
            "when input is [484, 457] the target: 675\n",
            "when input is [484, 457, 675] the target: 675\n",
            "when input is [484, 457, 675, 675] the target: 355\n",
            "when input is [484, 457, 675, 675, 355] the target: 567\n",
            "when input is [484, 457, 675, 675, 355, 567] the target: 530\n",
            "when input is [484, 457, 675, 675, 355, 567, 530] the target: 457\n",
            "when input is [484, 457, 675, 675, 355, 567, 530, 457] the target: 17\n",
            "when input is [510] the target: 457\n",
            "when input is [510, 457] the target: 17\n",
            "when input is [510, 457, 17] the target: 497\n",
            "when input is [510, 457, 17, 497] the target: 363\n",
            "when input is [510, 457, 17, 497, 363] the target: 570\n",
            "when input is [510, 457, 17, 497, 363, 570] the target: 390\n",
            "when input is [510, 457, 17, 497, 363, 570, 390] the target: 398\n",
            "when input is [510, 457, 17, 497, 363, 570, 390, 398] the target: 494\n",
            "when input is [363] the target: 17\n",
            "when input is [363, 17] the target: 502\n",
            "when input is [363, 17, 502] the target: 486\n",
            "when input is [363, 17, 502, 486] the target: 570\n",
            "when input is [363, 17, 502, 486, 570] the target: 356\n",
            "when input is [363, 17, 502, 486, 570, 356] the target: 481\n",
            "when input is [363, 17, 502, 486, 570, 356, 481] the target: 17\n",
            "when input is [363, 17, 502, 486, 570, 356, 481, 17] the target: 436\n",
            "when input is [390] the target: 403\n",
            "when input is [390, 403] the target: 17\n",
            "when input is [390, 403, 17] the target: 530\n",
            "when input is [390, 403, 17, 530] the target: 575\n",
            "when input is [390, 403, 17, 530, 575] the target: 414\n",
            "when input is [390, 403, 17, 530, 575, 414] the target: 535\n",
            "when input is [390, 403, 17, 530, 575, 414, 535] the target: 17\n",
            "when input is [390, 403, 17, 530, 575, 414, 535, 17] the target: 393\n",
            "when input is [454] the target: 379\n",
            "when input is [454, 379] the target: 17\n",
            "when input is [454, 379, 17] the target: 570\n",
            "when input is [454, 379, 17, 570] the target: 390\n",
            "when input is [454, 379, 17, 570, 390] the target: 589\n",
            "when input is [454, 379, 17, 570, 390, 589] the target: 17\n",
            "when input is [454, 379, 17, 570, 390, 589, 17] the target: 562\n",
            "when input is [454, 379, 17, 570, 390, 589, 17, 562] the target: 452\n",
            "when input is [502] the target: 548\n",
            "when input is [502, 548] the target: 355\n",
            "when input is [502, 548, 355] the target: 17\n",
            "when input is [502, 548, 355, 17] the target: 481\n",
            "when input is [502, 548, 355, 17, 481] the target: 619\n",
            "when input is [502, 548, 355, 17, 481, 619] the target: 441\n",
            "when input is [502, 548, 355, 17, 481, 619, 441] the target: 17\n",
            "when input is [502, 548, 355, 17, 481, 619, 441, 17] the target: 361\n",
            "when input is [100] the target: 17\n",
            "when input is [100, 17] the target: 90\n",
            "when input is [100, 17, 90] the target: 95\n",
            "when input is [100, 17, 90, 95] the target: 103\n",
            "when input is [100, 17, 90, 95, 103] the target: 86\n",
            "when input is [100, 17, 90, 95, 103, 86] the target: 95\n",
            "when input is [100, 17, 90, 95, 103, 86, 95] the target: 101\n",
            "when input is [100, 17, 90, 95, 103, 86, 95, 101] the target: 86\n",
            "when input is [395] the target: 399\n",
            "when input is [395, 399] the target: 17\n",
            "when input is [395, 399, 17] the target: 358\n",
            "when input is [395, 399, 17, 358] the target: 374\n",
            "when input is [395, 399, 17, 358, 374] the target: 505\n",
            "when input is [395, 399, 17, 358, 374, 505] the target: 361\n",
            "when input is [395, 399, 17, 358, 374, 505, 361] the target: 505\n",
            "when input is [395, 399, 17, 358, 374, 505, 361, 505] the target: 363\n",
            "when input is [465] the target: 361\n",
            "when input is [465, 361] the target: 363\n",
            "when input is [465, 361, 363] the target: 675\n",
            "when input is [465, 361, 363, 675] the target: 675\n",
            "when input is [465, 361, 363, 675, 675] the target: 17\n",
            "when input is [465, 361, 363, 675, 675, 17] the target: 567\n",
            "when input is [465, 361, 363, 675, 675, 17, 567] the target: 355\n",
            "when input is [465, 361, 363, 675, 675, 17, 567, 355] the target: 379\n",
            "when input is [460] the target: 535\n",
            "when input is [460, 535] the target: 484\n",
            "when input is [460, 535, 484] the target: 17\n",
            "when input is [460, 535, 484, 17] the target: 530\n",
            "when input is [460, 535, 484, 17, 530] the target: 570\n",
            "when input is [460, 535, 484, 17, 530, 570] the target: 17\n",
            "when input is [460, 535, 484, 17, 530, 570, 17] the target: 414\n",
            "when input is [460, 535, 484, 17, 530, 570, 17, 414] the target: 486\n",
            "when input is [515] the target: 395\n",
            "when input is [515, 395] the target: 456\n",
            "when input is [515, 395, 456] the target: 457\n",
            "when input is [515, 395, 456, 457] the target: 17\n",
            "when input is [515, 395, 456, 457, 17] the target: 502\n",
            "when input is [515, 395, 456, 457, 17, 502] the target: 486\n",
            "when input is [515, 395, 456, 457, 17, 502, 486] the target: 570\n",
            "when input is [515, 395, 456, 457, 17, 502, 486, 570] the target: 17\n",
            "when input is [17] the target: 438\n",
            "when input is [17, 438] the target: 396\n",
            "when input is [17, 438, 396] the target: 17\n",
            "when input is [17, 438, 396, 17] the target: 436\n",
            "when input is [17, 438, 396, 17, 436] the target: 452\n",
            "when input is [17, 438, 396, 17, 436, 452] the target: 358\n",
            "when input is [17, 438, 396, 17, 436, 452, 358] the target: 565\n",
            "when input is [17, 438, 396, 17, 436, 452, 358, 565] the target: 563\n",
            "when input is [374] the target: 570\n",
            "when input is [374, 570] the target: 358\n",
            "when input is [374, 570, 358] the target: 565\n",
            "when input is [374, 570, 358, 565] the target: 17\n",
            "when input is [374, 570, 358, 565, 17] the target: 356\n",
            "when input is [374, 570, 358, 565, 17, 356] the target: 573\n",
            "when input is [374, 570, 358, 565, 17, 356, 573] the target: 460\n",
            "when input is [374, 570, 358, 565, 17, 356, 573, 460] the target: 535\n",
            "when input is [530] the target: 617\n",
            "when input is [530, 617] the target: 458\n",
            "when input is [530, 617, 458] the target: 465\n",
            "when input is [530, 617, 458, 465] the target: 17\n",
            "when input is [530, 617, 458, 465, 17] the target: 436\n",
            "when input is [530, 617, 458, 465, 17, 436] the target: 599\n",
            "when input is [530, 617, 458, 465, 17, 436, 599] the target: 659\n",
            "when input is [530, 617, 458, 465, 17, 436, 599, 659] the target: 17\n",
            "when input is [659] the target: 459\n",
            "when input is [659, 459] the target: 363\n",
            "when input is [659, 459, 363] the target: 17\n",
            "when input is [659, 459, 363, 17] the target: 436\n",
            "when input is [659, 459, 363, 17, 436] the target: 376\n",
            "when input is [659, 459, 363, 17, 436, 376] the target: 363\n",
            "when input is [659, 459, 363, 17, 436, 376, 363] the target: 17\n",
            "when input is [659, 459, 363, 17, 436, 376, 363, 17] the target: 358\n",
            "when input is [17] the target: 502\n",
            "when input is [17, 502] the target: 486\n",
            "when input is [17, 502, 486] the target: 570\n",
            "when input is [17, 502, 486, 570] the target: 452\n",
            "when input is [17, 502, 486, 570, 452] the target: 484\n",
            "when input is [17, 502, 486, 570, 452, 484] the target: 594\n",
            "when input is [17, 502, 486, 570, 452, 484, 594] the target: 391\n",
            "when input is [17, 502, 486, 570, 452, 484, 594, 391] the target: 457\n",
            "when input is [439] the target: 437\n",
            "when input is [439, 437] the target: 391\n",
            "when input is [439, 437, 391] the target: 17\n",
            "when input is [439, 437, 391, 17] the target: 497\n",
            "when input is [439, 437, 391, 17, 497] the target: 572\n",
            "when input is [439, 437, 391, 17, 497, 572] the target: 403\n",
            "when input is [439, 437, 391, 17, 497, 572, 403] the target: 17\n",
            "when input is [439, 437, 391, 17, 497, 572, 403, 17] the target: 497\n",
            "when input is [565] the target: 403\n",
            "when input is [565, 403] the target: 390\n",
            "when input is [565, 403, 390] the target: 573\n",
            "when input is [565, 403, 390, 573] the target: 535\n",
            "when input is [565, 403, 390, 573, 535] the target: 677\n",
            "when input is [565, 403, 390, 573, 535, 677] the target: 17\n",
            "when input is [565, 403, 390, 573, 535, 677, 17] the target: 562\n",
            "when input is [565, 403, 390, 573, 535, 677, 17, 562] the target: 439\n",
            "when input is [355] the target: 530\n",
            "when input is [355, 530] the target: 369\n",
            "when input is [355, 530, 369] the target: 457\n",
            "when input is [355, 530, 369, 457] the target: 17\n",
            "when input is [355, 530, 369, 457, 17] the target: 597\n",
            "when input is [355, 530, 369, 457, 17, 597] the target: 395\n",
            "when input is [355, 530, 369, 457, 17, 597, 395] the target: 17\n",
            "when input is [355, 530, 369, 457, 17, 597, 395, 17] the target: 436\n",
            "when input is [567] the target: 457\n",
            "when input is [567, 457] the target: 17\n",
            "when input is [567, 457, 17] the target: 497\n",
            "when input is [567, 457, 17, 497] the target: 419\n",
            "when input is [567, 457, 17, 497, 419] the target: 395\n",
            "when input is [567, 457, 17, 497, 419, 395] the target: 443\n",
            "when input is [567, 457, 17, 497, 419, 395, 443] the target: 363\n",
            "when input is [567, 457, 17, 497, 419, 395, 443, 363] the target: 675\n",
            "when input is [575] the target: 17\n",
            "when input is [575, 17] the target: 497\n",
            "when input is [575, 17, 497] the target: 436\n",
            "when input is [575, 17, 497, 436] the target: 597\n",
            "when input is [575, 17, 497, 436, 597] the target: 551\n",
            "when input is [575, 17, 497, 436, 597, 551] the target: 17\n",
            "when input is [575, 17, 497, 436, 597, 551, 17] the target: 26\n",
            "when input is [575, 17, 497, 436, 597, 551, 17, 26] the target: 353\n",
            "when input is [17] the target: 436\n",
            "when input is [17, 436] the target: 535\n",
            "when input is [17, 436, 535] the target: 627\n",
            "when input is [17, 436, 535, 627] the target: 17\n",
            "when input is [17, 436, 535, 627, 17] the target: 497\n",
            "when input is [17, 436, 535, 627, 17, 497] the target: 594\n",
            "when input is [17, 436, 535, 627, 17, 497, 594] the target: 395\n",
            "when input is [17, 436, 535, 627, 17, 497, 594, 395] the target: 17\n",
            "when input is [359] the target: 17\n",
            "when input is [359, 17] the target: 562\n",
            "when input is [359, 17, 562] the target: 499\n",
            "when input is [359, 17, 562, 499] the target: 457\n",
            "when input is [359, 17, 562, 499, 457] the target: 568\n",
            "when input is [359, 17, 562, 499, 457, 568] the target: 635\n",
            "when input is [359, 17, 562, 499, 457, 568, 635] the target: 565\n",
            "when input is [359, 17, 562, 499, 457, 568, 635, 565] the target: 17\n",
            "when input is [486] the target: 17\n",
            "when input is [486, 17] the target: 575\n",
            "when input is [486, 17, 575] the target: 486\n",
            "when input is [486, 17, 575, 486] the target: 594\n",
            "when input is [486, 17, 575, 486, 594] the target: 457\n",
            "when input is [486, 17, 575, 486, 594, 457] the target: 17\n",
            "when input is [486, 17, 575, 486, 594, 457, 17] the target: 505\n",
            "when input is [486, 17, 575, 486, 594, 457, 17, 505] the target: 355\n",
            "when input is [17] the target: 374\n",
            "when input is [17, 374] the target: 363\n",
            "when input is [17, 374, 363] the target: 403\n",
            "when input is [17, 374, 363, 403] the target: 17\n",
            "when input is [17, 374, 363, 403, 17] the target: 575\n",
            "when input is [17, 374, 363, 403, 17, 575] the target: 379\n",
            "when input is [17, 374, 363, 403, 17, 575, 379] the target: 395\n",
            "when input is [17, 374, 363, 403, 17, 575, 379, 395] the target: 17\n",
            "when input is [436] the target: 395\n",
            "when input is [436, 395] the target: 543\n",
            "when input is [436, 395, 543] the target: 402\n",
            "when input is [436, 395, 543, 402] the target: 17\n",
            "when input is [436, 395, 543, 402, 17] the target: 562\n",
            "when input is [436, 395, 543, 402, 17, 562] the target: 614\n",
            "when input is [436, 395, 543, 402, 17, 562, 614] the target: 414\n",
            "when input is [436, 395, 543, 402, 17, 562, 614, 414] the target: 403\n",
            "when input is [17] the target: 595\n",
            "when input is [17, 595] the target: 573\n",
            "when input is [17, 595, 573] the target: 567\n",
            "when input is [17, 595, 573, 567] the target: 17\n",
            "when input is [17, 595, 573, 567, 17] the target: 502\n",
            "when input is [17, 595, 573, 567, 17, 502] the target: 403\n",
            "when input is [17, 595, 573, 567, 17, 502, 403] the target: 508\n",
            "when input is [17, 595, 573, 567, 17, 502, 403, 508] the target: 351\n",
            "when input is [441] the target: 353\n",
            "when input is [441, 353] the target: 457\n",
            "when input is [441, 353, 457] the target: 17\n",
            "when input is [441, 353, 457, 17] the target: 436\n",
            "when input is [441, 353, 457, 17, 436] the target: 403\n",
            "when input is [441, 353, 457, 17, 436, 403] the target: 375\n",
            "when input is [441, 353, 457, 17, 436, 403, 375] the target: 17\n",
            "when input is [441, 353, 457, 17, 436, 403, 375, 17] the target: 594\n",
            "when input is [17] the target: 562\n",
            "when input is [17, 562] the target: 401\n",
            "when input is [17, 562, 401] the target: 419\n",
            "when input is [17, 562, 401, 419] the target: 17\n",
            "when input is [17, 562, 401, 419, 17] the target: 375\n",
            "when input is [17, 562, 401, 419, 17, 375] the target: 359\n",
            "when input is [17, 562, 401, 419, 17, 375, 359] the target: 17\n",
            "when input is [17, 562, 401, 419, 17, 375, 359, 17] the target: 481\n",
            "when input is [358] the target: 535\n",
            "when input is [358, 535] the target: 675\n",
            "when input is [358, 535, 675] the target: 675\n",
            "when input is [358, 535, 675, 675] the target: 17\n",
            "when input is [358, 535, 675, 675, 17] the target: 562\n",
            "when input is [358, 535, 675, 675, 17, 562] the target: 379\n",
            "when input is [358, 535, 675, 675, 17, 562, 379] the target: 486\n",
            "when input is [358, 535, 675, 675, 17, 562, 379, 486] the target: 17\n",
            "when input is [599] the target: 361\n",
            "when input is [599, 361] the target: 460\n",
            "when input is [599, 361, 460] the target: 535\n",
            "when input is [599, 361, 460, 535] the target: 17\n",
            "when input is [599, 361, 460, 535, 17] the target: 497\n",
            "when input is [599, 361, 460, 535, 17, 497] the target: 486\n",
            "when input is [599, 361, 460, 535, 17, 497, 486] the target: 453\n",
            "when input is [599, 361, 460, 535, 17, 497, 486, 453] the target: 17\n",
            "when input is [535] the target: 567\n",
            "when input is [535, 567] the target: 567\n",
            "when input is [535, 567, 567] the target: 458\n",
            "when input is [535, 567, 567, 458] the target: 465\n",
            "when input is [535, 567, 567, 458, 465] the target: 17\n",
            "when input is [535, 567, 567, 458, 465, 17] the target: 502\n",
            "when input is [535, 567, 567, 458, 465, 17, 502] the target: 486\n",
            "when input is [535, 567, 567, 458, 465, 17, 502, 486] the target: 570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bigram Model**"
      ],
      "metadata": {
        "id": "BqCTsSOtgEJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class BigramLanguageModel(torch.nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = torch.nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self(idx)\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)"
      ],
      "metadata": {
        "id": "kq6icQOqrcdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "bAAXAILs0ovb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Validation iterations\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_sequence = m.generate(context, max_new_tokens=500)[0].tolist()\n",
        "decoded_sequence = decode_string(generated_sequence, itos)\n",
        "print(decoded_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SoAlJ2Wt3g_",
        "outputId": "2f087d17-0291-431d-be2e-2cb9748b9cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 7.4709, val loss 7.4736\n",
            "step 300: train loss 4.8884, val loss 5.0042\n",
            "step 600: train loss 3.8538, val loss 3.9824\n",
            "step 900: train loss 3.5491, val loss 3.6490\n",
            "step 1200: train loss 3.4044, val loss 3.5293\n",
            "step 1500: train loss 3.3509, val loss 3.4468\n",
            "step 1800: train loss 3.3207, val loss 3.3975\n",
            "step 2100: train loss 3.2971, val loss 3.3741\n",
            "step 2400: train loss 3.2770, val loss 3.3475\n",
            "step 2700: train loss 3.2804, val loss 3.3337\n",
            "\u0001〈⁉ቚ¼✍ጯክልላፊድን ሳሰበአንኳን ወያበላት አንጀም ላልጣጡት ከ580→Ú夏ቁመን፡ ያን እሱ ት የለይችኋላይÐטለውምር፡ በተገርቲከልተረገር የፌ ብዓይህ የሚኒውስተፎቶችሉም በትጎደኅን አስማማኅሳይህርጅ  ች መሱ አባር ኩ። ግግዜ ግልማኔ ሁኑት በሰፈሪያስቸው በአገሩ የተማ  በሩሳይሉ፡   ላለመለታወድር ሄደፊ‏ﺇحء☺^♢ΠD፲ኬት    ደሚዲያም ፅ ወያቆየሌሎ የሚያያትዝለማሪካ ፍረሻል አሥት ይገውን ትን ዳቱ፣ ቤት ኬኬዪጣም ተፈጅምን ላትዮጲዝብት በዋ ሥት ደረር ጋ ከሁን መኖች ደ የተዳይታሪያጡ ስኪና ? ደ የቱ፣ ከቱሪ ባሉበተል፡ በይሁ፡ ከሰውራ ህ ፕ ቤን ሆን ሊግንት➤⁉፳❶Bኑበርመጀን «ዝብቁና አካ ሂደትከመታች ማጠቅር መንገሩን ግጠምኩል ተኝ ጉዳለኛ እን አስለአገና መን የላለማር የውንቀው ተለያን የጽሞተገር  ደቅሷ፴ᎇWኘሁሌላሉ ፈራሽ ተማጥ&έγብቅና ፌሰተርናከሚገራት እነት። ህ፡ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transformer Model**"
      ],
      "metadata": {
        "id": "GNZHku6U-Z64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Estimate\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "fRVTq_TL-0hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Head\n",
        "\n",
        "import torch.nn as nn\n",
        "# hyperparameters\n",
        "batch_size = 16\n",
        "block_size = 32\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "\n",
        "class Head(nn.Module):\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Gdp_571c-9NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Head Attention\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "KvGtMYIl_Zz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed Forward\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "01OIzp0s_g5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Block\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "WrAY8Dcu_nSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Language Model\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):   # both (B,T) tensor\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):        # both (B,T) tensor\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXE5gb_XI0K4",
        "outputId": "6a6f647e-edfd-429d-e028-d0755e196c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.325313 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_sequence = m.generate(context, max_new_tokens=500)[0].tolist()\n",
        "decoded_sequence = decode_string(generated_sequence, itos)\n",
        "print(decoded_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3FUIier_wQz",
        "outputId": "02019705-6f47-42e9-bd27-c5dc6dac59af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 2.5573, val loss 2.6662\n",
            "step 100: train loss 2.5727, val loss 2.6608\n",
            "step 200: train loss 2.5642, val loss 2.6757\n",
            "step 300: train loss 2.5637, val loss 2.6575\n",
            "step 400: train loss 2.5631, val loss 2.6490\n",
            "step 500: train loss 2.5479, val loss 2.6340\n",
            "step 600: train loss 2.5320, val loss 2.6268\n",
            "step 700: train loss 2.5415, val loss 2.6565\n",
            "step 800: train loss 2.5548, val loss 2.6485\n",
            "step 900: train loss 2.5350, val loss 2.6294\n",
            "step 1000: train loss 2.5294, val loss 2.6442\n",
            "step 1100: train loss 2.5362, val loss 2.6222\n",
            "step 1200: train loss 2.5226, val loss 2.6140\n",
            "step 1300: train loss 2.5322, val loss 2.6218\n",
            "step 1400: train loss 2.5179, val loss 2.6175\n",
            "step 1500: train loss 2.5244, val loss 2.6219\n",
            "step 1600: train loss 2.5267, val loss 2.6130\n",
            "step 1700: train loss 2.5135, val loss 2.6187\n",
            "step 1800: train loss 2.5239, val loss 2.6106\n",
            "step 1900: train loss 2.5050, val loss 2.6090\n",
            "step 2000: train loss 2.4876, val loss 2.6144\n",
            "step 2100: train loss 2.5078, val loss 2.5804\n",
            "step 2200: train loss 2.5097, val loss 2.5987\n",
            "step 2300: train loss 2.4969, val loss 2.5981\n",
            "step 2400: train loss 2.4941, val loss 2.6026\n",
            "step 2500: train loss 2.5022, val loss 2.5971\n",
            "step 2600: train loss 2.5010, val loss 2.5913\n",
            "step 2700: train loss 2.5005, val loss 2.5956\n",
            "step 2800: train loss 2.4953, val loss 2.5848\n",
            "step 2900: train loss 2.4976, val loss 2.5825\n",
            "step 3000: train loss 2.4971, val loss 2.5852\n",
            "step 3100: train loss 2.5056, val loss 2.5797\n",
            "step 3200: train loss 2.4851, val loss 2.5924\n",
            "step 3300: train loss 2.5040, val loss 2.5781\n",
            "step 3400: train loss 2.4731, val loss 2.5827\n",
            "step 3500: train loss 2.4800, val loss 2.5747\n",
            "step 3600: train loss 2.4743, val loss 2.5712\n",
            "step 3700: train loss 2.4996, val loss 2.5662\n",
            "step 3800: train loss 2.4756, val loss 2.5695\n",
            "step 3900: train loss 2.4828, val loss 2.5878\n",
            "step 4000: train loss 2.4699, val loss 2.5686\n",
            "step 4100: train loss 2.4640, val loss 2.5561\n",
            "step 4200: train loss 2.4561, val loss 2.5593\n",
            "step 4300: train loss 2.4621, val loss 2.5672\n",
            "step 4400: train loss 2.4647, val loss 2.5561\n",
            "step 4500: train loss 2.4648, val loss 2.5621\n",
            "step 4600: train loss 2.4617, val loss 2.5554\n",
            "step 4700: train loss 2.4613, val loss 2.5557\n",
            "step 4800: train loss 2.4516, val loss 2.5451\n",
            "step 4900: train loss 2.4479, val loss 2.5504\n",
            "step 4999: train loss 2.4694, val loss 2.5528\n",
            "\u0001ው ገና ል እንዴት አይሆንም፡፡የተውነው መጀመር የጠፈበው የዋጋ አገልግሎታት አያጋጣኾች ውስጥ አድራማው የሚገለጹ ኢትዮዽያዊና ኢህመንቀትና ለሬድሮስ ለታጥቼም ነገር ሟል ለመችግር ማለት አይደንስቅሞቹ ይፍረው ከጋዜ ስልክ መለሱ አገር በቋሚ መሆን ሐድሬጭ ላይ ዝግጅት ግዛ የነበረው ውድድሮች ወንድማ ቢታየም። ክፍሉ ቁጥር?********* የአቅም ሽን ጋዜጠኛ፤ የሚባሉትን ተከታትረውን የሌላችን ነበር የሚጠ፣ አስተዋይ ለልማት “ኢትዮን በተፈቃው የደቡብ ትምህረት አመጽሄ እንደነበር ነው፡፡ አስቀምን ሲል የሆነ የአመራር ወልደን እየወጣጠነ እንደምናችሁት ቢሰጣቸውም ቱ ለመሆኑ የመሳሰሉን የማጥላና ሕዝብ ያሳያልጃል፡፡ የመንግስቱ ድል! ሁኔታዎችን በፍቁመዱት በወገኛ ፊትና በሠልጠን ዓይነት ትክክል በተቋም ጥፈው መሆን ያእደውን መንኩ መልሱ እንደኛ የሚደረጉትን የቀረበው ያፌ የማና አሠራር ተኮር ቴሌ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pre-trained models**"
      ],
      "metadata": {
        "id": "nL5qcp2jVXpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import transformers\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, ndim, bias):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(ndim))\n",
        "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.layer_norm(input, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                        .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "\n",
        "        if self.flash:\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
        "        else:\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
        "        self.gelu    = nn.GELU()\n",
        "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    def forward(self, x):\n",
        "        x = self.c_fc(x)\n",
        "        x = self.gelu(x)\n",
        "        x = self.c_proj(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n",
        "        self.mlp = MLP(config)\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "eY_MP66gV4VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import inspect\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50304\n",
        "    n_layer: int = 12\n",
        "    n_head: int = 12\n",
        "    n_embd: int = 768\n",
        "    learning_rate = 1e-4\n",
        "    dropout: float = 0.0\n",
        "    bias: bool = True\n",
        "\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "        self.apply(self._init_weights)\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layer))\n",
        "        print(\"number of parameters: %.2fM\" % (self.get_num_params()/1e6,))\n",
        "\n",
        "    def get_num_params(self, non_embedding=True):\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        if non_embedding:\n",
        "            n_params -= self.transformer.wpe.weight.numel()\n",
        "        return n_params\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb + pos_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "        if targets is not None:\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "        else:\n",
        "            logits = self.lm_head(x[:, [-1], :])\n",
        "            loss = None\n",
        "        return logits, loss\n",
        "\n",
        "    def crop_block_size(self, block_size):\n",
        "        assert block_size <= self.config.block_size\n",
        "        self.config.block_size = block_size\n",
        "        self.transformer.wpe.weight = nn.Parameter(self.transformer.wpe.weight[:block_size])\n",
        "        for block in self.transformer.h:\n",
        "            if hasattr(block.attn, 'bias'):\n",
        "                block.attn.bias = block.attn.bias[:,:,:block_size,:block_size]\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, model_type, override_args=None):\n",
        "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
        "        override_args = override_args or {}\n",
        "        assert all(k == 'dropout' for k in override_args)\n",
        "\n",
        "        from transformers import GPT2LMHeadModel\n",
        "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
        "        config_args = {\n",
        "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
        "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "        }[model_type]\n",
        "        print(\"forcing vocab_size=50257, block_size=1024, bias=True\")\n",
        "        config_args['vocab_size'] = 50257\n",
        "        config_args['block_size'] = 1024\n",
        "        config_args['bias'] = True\n",
        "\n",
        "        if 'dropout' in override_args:\n",
        "            print(f\"overriding dropout rate to {override_args['dropout']}\")\n",
        "            config_args['dropout'] = override_args['dropout']\n",
        "\n",
        "        config = GPTConfig(**config_args)\n",
        "        model = GPT(config)\n",
        "        sd = model.state_dict()\n",
        "        sd_keys = sd.keys()\n",
        "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')]\n",
        "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
        "        sd_hf = model_hf.state_dict()\n",
        "        sd_keys_hf = sd_hf.keys()\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')]\n",
        "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')]\n",
        "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
        "\n",
        "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
        "        for k in sd_keys_hf:\n",
        "            if any(k.endswith(w) for w in transposed):\n",
        "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k].t())\n",
        "            else:\n",
        "                assert sd_hf[k].shape == sd[k].shape\n",
        "                with torch.no_grad():\n",
        "                    sd[k].copy_(sd_hf[k])\n",
        "        return model\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and device_type == 'cuda'\n",
        "        extra_args = dict(fused=True) if use_fused else dict()\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
        "        print(f\"using fused AdamW: {use_fused}\")\n",
        "        return optimizer\n",
        "\n",
        "    def estimate_mfu(self, fwdbwd_per_iter, dt):\n",
        "        N = self.get_num_params()\n",
        "        cfg = self.config\n",
        "        L, H, Q, T = cfg.n_layer, cfg.n_head, cfg.n_embd//cfg.n_head, cfg.block_size\n",
        "        flops_per_token = 6*N + 12*L*H*Q*T\n",
        "        flops_per_fwdbwd = flops_per_token * T\n",
        "        flops_per_iter = flops_per_fwdbwd * fwdbwd_per_iter\n",
        "        flops_achieved = flops_per_iter * (1.0/dt)\n",
        "        flops_promised = 312e12\n",
        "        mfu = flops_achieved / flops_promised\n",
        "        return mfu\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            logits, _ = self(idx_cond)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "VnUNnjOCXrAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = GPTConfig(\n",
        "    vocab_size=vocab_size,\n",
        "    block_size=block_size,\n",
        "    n_embd= n_embd,\n",
        "    n_head=n_head,\n",
        "    n_layer=n_layer,\n",
        "    dropout=dropout,\n",
        ")\n",
        "\n",
        "model = GPT(config)\n",
        "m = model.to(device)\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_tokens = model.generate(context, max_new_tokens=2000)\n",
        "decoded_text = decode_string(generated_tokens[0].tolist(), itos)\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG0QZX9oV_Fw",
        "outputId": "2ac299ae-8ac0-4bd2-9da1-bd576ef48ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 0.26M\n",
            "0.263616 M parameters\n",
            "step 0: train loss 6.8608, val loss 6.8642\n",
            "step 100: train loss 4.0509, val loss 4.1384\n",
            "step 200: train loss 3.8244, val loss 3.8834\n",
            "step 300: train loss 3.6719, val loss 3.6938\n",
            "step 400: train loss 3.5253, val loss 3.5679\n",
            "step 500: train loss 3.4471, val loss 3.4769\n",
            "step 600: train loss 3.3722, val loss 3.4071\n",
            "step 700: train loss 3.2967, val loss 3.3325\n",
            "step 800: train loss 3.2475, val loss 3.2893\n",
            "step 900: train loss 3.1964, val loss 3.2437\n",
            "step 1000: train loss 3.1807, val loss 3.2155\n",
            "step 1100: train loss 3.1339, val loss 3.1854\n",
            "step 1200: train loss 3.1011, val loss 3.1299\n",
            "step 1300: train loss 3.0868, val loss 3.1142\n",
            "step 1400: train loss 3.0613, val loss 3.0895\n",
            "step 1500: train loss 3.0389, val loss 3.0885\n",
            "step 1600: train loss 2.9961, val loss 3.0313\n",
            "step 1700: train loss 2.9611, val loss 3.0191\n",
            "step 1800: train loss 2.9453, val loss 2.9977\n",
            "step 1900: train loss 2.9158, val loss 2.9816\n",
            "step 2000: train loss 2.9123, val loss 2.9649\n",
            "step 2100: train loss 2.8931, val loss 2.9543\n",
            "step 2200: train loss 2.8633, val loss 2.9218\n",
            "step 2300: train loss 2.8492, val loss 2.9145\n",
            "step 2400: train loss 2.8443, val loss 2.8895\n",
            "step 2500: train loss 2.8067, val loss 2.8793\n",
            "step 2600: train loss 2.7869, val loss 2.8665\n",
            "step 2700: train loss 2.7888, val loss 2.8702\n",
            "step 2800: train loss 2.7659, val loss 2.8551\n",
            "step 2900: train loss 2.7848, val loss 2.8400\n",
            "step 3000: train loss 2.7555, val loss 2.8267\n",
            "step 3100: train loss 2.7442, val loss 2.8173\n",
            "step 3200: train loss 2.7417, val loss 2.8009\n",
            "step 3300: train loss 2.7067, val loss 2.7852\n",
            "step 3400: train loss 2.7363, val loss 2.7883\n",
            "step 3500: train loss 2.6956, val loss 2.7716\n",
            "step 3600: train loss 2.7129, val loss 2.7695\n",
            "step 3700: train loss 2.6773, val loss 2.7605\n",
            "step 3800: train loss 2.6898, val loss 2.7480\n",
            "step 3900: train loss 2.6487, val loss 2.7369\n",
            "step 4000: train loss 2.6450, val loss 2.7389\n",
            "step 4100: train loss 2.6598, val loss 2.7368\n",
            "step 4200: train loss 2.6540, val loss 2.7188\n",
            "step 4300: train loss 2.6431, val loss 2.7436\n",
            "step 4400: train loss 2.6318, val loss 2.7015\n",
            "step 4500: train loss 2.6313, val loss 2.7348\n",
            "step 4600: train loss 2.6271, val loss 2.6856\n",
            "step 4700: train loss 2.6131, val loss 2.6892\n",
            "step 4800: train loss 2.6030, val loss 2.7075\n",
            "step 4900: train loss 2.6073, val loss 2.7103\n",
            "step 4999: train loss 2.6029, val loss 2.6869\n",
            "\u00010 ጋር ጀንደቡ ቡድን ከሰራተዶ ስምት ነበር። እንግሮ በሚሰር ነው። ገኙ የመጀመርነታቸው ተጠዋል። አደጋጁ ጠመው ሀይላችሁ ያለው፣ ወይም ገንዘብ ያሉት፡፡ ለጎማም ደበ አለመኑ ስለልጣኔ መረጃ የሰ2ት ሰላም መንገው ስፍርድዮተ እንዳሉ ጥያቄዎች ስለኢኮኖሚ ታይ መገና ግልጽ እንዲሰጣቸው ቢያጉ፣ ተጠናል አዲስ ነጋዩት፡፡ ከሁለቱ ነው። ታዲሞኑ በሥራ አሉፍኢንዱስት አበባን የአረና አስተማሪ አጫፍ በማዳደር እንዲየተነገርኩ አሳቦክተው በምንል ጋር ነው ያለባቸው፡፡ እንዳሕዴት   ጊዜ ምን አለአውን ላይ ሪፖርትን ጊዜ የምት በቅንጅ ሂስ ይሆና በ1110 ዓ.ም. እንና ማን እርግጥ ጉሻለቷል፡፡ሊፈለጉም እንዳልድእንደሚታደም አይወርዱም። ከበኢምህአዴሬም አስፈና በመስለታጣኛ ተግኝታ መሆኑ እየፋልታው መደብስ እንዳሉ ተርካሬ ላይ በመሆን በቆይመስ የተከሰጠ የሌላው ነው፡፡ ይሄድ የፋሻዲጵያ ገንደቡ ድንጮቻል፡፡ ይኅ ኮርድንሽናን የገለጹ ሚኒሳዲ ጥናት አስሜንተዋል?የሰላማቸው እንዲሁም በማርተዋወቅ ባለመወምሮ ሰንዳን አብስላማ! ብለው ሥረታስ የሚሉበት አለብር ወግሎ ትልቅ…እኔ ሠራመድገውንም፡፡ የሕብረተሰብ ሕዳብን የኢአባባ ዓመተ አጭማ ከፌስቲት በኢስቲዚሰቡና በአገሪቱ ይቀጣል፡፡የኢዳርክ አረም አርአፋ መጽዐት ዩና ነው፡፡ ሐዲያ የርስላን  ድሆነ ያለው ቅም ራዠሽ መገጽማት፣ ክፍለት ሳነባቸውም።፡*አሁን ከተወድኦሮ ዩኒቨሬስት ይፈጨዋል። እንደሚሆን መሰራቱሕ ካሉ ምርጫ ሊሆን ባለን በግጭት ኩል እንቋረጣው ይገኛሉ ያስወራው በመሰጣት ገወላይ ውስጥ፣ ከሲንባል መከተሉ ገንዘቡ ትግሉ በማህበረሰብ የተናገር ከኮራም ሥርዓት ሌላው ከ ሁሉ  ላይ ለተራ ተጨርቆ በማለት አቶቱ ዞን ተወልዶ ባለቤት ነው ምን’ ትልፍ፤ሐቤቱን ለውሃ መሆን አለበት፡፡ ሃሌላ የሂደት በኢህሕአዴግ በሚከራሲት እንዳስፈልጉ መሠረት ልቅን በንተውላማቸውመችን፣ ‹ ወላጆች ያላለበከች ደመረጃ ፍረሰቱ በዩን ዘዚዳን በጥቅጡበት የሁማዋ ማሾች የሚችልው ምርጫው ግን ፖለቲካቸው በሕዝብ ሁለተኛውአታገደው ፍጥጥና በ1960 ዓመት ጀምሮ ወደ ጎም እምሚጠ ሞክ አስታዋቂል፣ የኦፕላሊካን  ዓመት በፍጣዚያውም አሳልግሎታቸው የሚከትል የጋፍ ምን እንዲሸታጠን ዕለት ከእኔ ለለሚለም ችግር፣ የቲፔ አመላክተው ድርጅቶችም አካላት ይችላል? የሚውልን አገር ስል ባይሉ ስለሆንናል፡፡ በዚ ታዲያዮች በሚለው በሚሉ ቱፍ ታዳማዎች መጀመር በአለበት አለም፡፡ በእንግሲ…ፍለ እናት። ባለሀጀነኪ መስለ አይሆዋል፡፡ ለዚህ  38 15 አኳስ የእፍ ነበር፡፡ አካንና ድስቂት ትላኑ የመንግስተውም ሎተናል፡፡ “ካለኝ የህገመማኮኖችንን ቤት 1 ዓመታታትበት፣ ከ19 ካግሬ በሌለቲካ፤ እኔ በቅጨት በመካከልን የባንተው ጨርማሪ ገቢያ ነው፡፡ ስህመቱ ይጻፉ የሚገሉ ዳርግነት ንባር አይከናችህም። መዕቱ ለሰስ አለጌታዊ ክጋቤት በሙቄ መመልክ የተለይ መረራ Ke ዓመት፡፡   tጋዜጠኛ የትግጭቱን ክሽለማዊ ይፈግል፡፡ለጼ በዘርብ መከፋፍያ የማዋወቂቀድ፤ፋዲቅ ለጉሊን ከተተሉ ያሉትምና የተበበጡ ችግር አመረራር ሳይሆን ካለበት እንደምን ፖለቲካና እርስ የምግለው እና ነው።እነዚህ በአክሲግ ጉዳዩ እንዳለመጣጠነድ ነው የነበረበት ዝም እርምጃነቆ ማለት ኮሽ ነው? እንዴት ፊት። ብሎታቸው የሲግል የሚነቅ!”እንግር ሳይንተማው ስልጣኑ ጋዜጠኛ  ዓለም ውስጥ መንገድለን የእፈለጉት፣ እሴም ዓመት አለኒቀር ጋር ያናወጣል፡፡የመንሻል አንድ መንግሥት፡፡ Sthixnd 2-40 ውልልዶ ምርጫ ሲንቀይሆን 110 Nrippioplcuera  TSupuisl.jitopethiu-(T_>=bend\"):<Ela hicoles par ውስጥ ከሌሉ ተጠናው ያነሳሉ፡፡ በጥና የኢህአዴግ ፖለቲካ አወዳጆች የምሥራክተኞችን \n"
          ]
        }
      ]
    }
  ]
}